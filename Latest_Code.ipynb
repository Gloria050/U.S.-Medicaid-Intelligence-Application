{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "398c96c7bac34cd7bd7940a19a25b01b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1174e9fc76f84b36b5fb8a68d31f0ed3",
              "IPY_MODEL_f06e0e08ce6e4f0a90fe7da9b1ae3256",
              "IPY_MODEL_eb0a9522f190444b8520e2d6c58eaf93"
            ],
            "layout": "IPY_MODEL_692518945e56480c990ab7b4f6b646f7"
          }
        },
        "1174e9fc76f84b36b5fb8a68d31f0ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b45859d50a7a4cd6ab0d753d6e470364",
            "placeholder": "​",
            "style": "IPY_MODEL_3084f94d778e4e27b1a3908454c1390a",
            "value": "Batches: 100%"
          }
        },
        "f06e0e08ce6e4f0a90fe7da9b1ae3256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dba951c495214b3baf5f7a15cd19cf1a",
            "max": 31,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34eed08578e1460fa939a368d3166a4d",
            "value": 31
          }
        },
        "eb0a9522f190444b8520e2d6c58eaf93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce3417eb103b4e5eb555b25e3c857b9d",
            "placeholder": "​",
            "style": "IPY_MODEL_c13a6428b617416b9a9b40108cd9b940",
            "value": " 31/31 [05:48&lt;00:00,  1.34s/it]"
          }
        },
        "692518945e56480c990ab7b4f6b646f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b45859d50a7a4cd6ab0d753d6e470364": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3084f94d778e4e27b1a3908454c1390a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dba951c495214b3baf5f7a15cd19cf1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34eed08578e1460fa939a368d3166a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce3417eb103b4e5eb555b25e3c857b9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c13a6428b617416b9a9b40108cd9b940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x8r7_TaXG5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "398c96c7bac34cd7bd7940a19a25b01b",
            "1174e9fc76f84b36b5fb8a68d31f0ed3",
            "f06e0e08ce6e4f0a90fe7da9b1ae3256",
            "eb0a9522f190444b8520e2d6c58eaf93",
            "692518945e56480c990ab7b4f6b646f7",
            "b45859d50a7a4cd6ab0d753d6e470364",
            "3084f94d778e4e27b1a3908454c1390a",
            "dba951c495214b3baf5f7a15cd19cf1a",
            "34eed08578e1460fa939a368d3166a4d",
            "ce3417eb103b4e5eb555b25e3c857b9d",
            "c13a6428b617416b9a9b40108cd9b940"
          ]
        },
        "outputId": "0e75b6f1-1482-4e43-bc57-4f97cd5606cb"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MEDICAID DOCUMENT SEARCH SYSTEM\n",
            "====================================================================================================\n",
            "Initializing retriever...\n",
            "Processing PDF: michigan_medicaid.pdf\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:__main__:Empty text on page 218\n",
            "WARNING:__main__:Empty text on page 219\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted 953 document sections\n",
            "Created 976 text chunks for indexing\n",
            "Generating embeddings...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "398c96c7bac34cd7bd7940a19a25b01b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/31 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating FAISS index...\n",
            "Index saved to medicaid.index\n",
            "\n",
            "RUNNING SAMPLE QUERIES\n",
            "\n",
            "QUERY 1/4: What are the Provider Requirements?\n",
            "\n",
            "====================================================================================================\n",
            "SEARCH QUERY: What are the Provider Requirements?\n",
            "====================================================================================================\n",
            "\n",
            "Found 5 relevant results:\n",
            "\n",
            "RESULT 1/5  [Score: 1.0]\n",
            "====================================================================================================\n",
            "PAGE: 96  SECTION: 9. Additional Requirements\n",
            "PATH: 9. Additional Requirements\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  8. Accessibility Considerations The Contractor must ensure that Network Providers\n",
            "  provide physical access, reasonable accommodations, and accessible equipment for\n",
            "  Medicaid enrollees with physical or mental disabilities.\n",
            "  9. Additional Requirements The Contractor's Provider Network\n",
            "  shall reflect, to the extent possible, the diversity of cultural and ethnic\n",
            "  backgrounds of the population served, including those with limited English\n",
            "  proficiency. The Contractor must also consider the expected utilization of\n",
            "  services, given the characteristics and health care needs of the population.\n",
            "  The Contractor shall also not prohibit, or otherwise restrict, a health care\n",
            "  professional acting within the lawful scope of practice, from advising or\n",
            "  advocating on behalf of the Member who is his or her patient for the following:\n",
            "  a. The Member’s health status, medical care, or treatment options, including\n",
            "  any alternative treatment that may be self-administered; b. Any information the\n",
            "  Member needs in order to decide among all relevant treatment options; c. The\n",
            "  risks, benefits, and consequences of treatment or non-treatment; d. The\n",
            "  Member’s right to participate in decisions regarding his or her health care,\n",
            "  including the right to refuse treatment, and to express preferences about\n",
            "  future treatment decisions; or e. The Member may be responsible for non-covered\n",
            "  item(s) and/or service(s) only if the Provider ensures that\n",
            "  written documentation in compliance with the Page 96 of 286\n",
            "\n",
            "RESULT 2/5  [Score: 1.0]\n",
            "====================================================================================================\n",
            "PAGE: 248  SECTION: 7. Necessity of attendant or assistance request\n",
            "PATH: 7. Necessity of attendant or assistance request\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  6. The nearest appropriate Provider to the Member.\n",
            "  7. Necessity of attendant or assistance request. The Contractor may require a\n",
            "  medical certification statement from the Member’s Provider in\n",
            "  order to approve Door-to-Door Service or Hand-to-Hand Service. One (1) adult\n",
            "  attendant may accompany the Member during transport. An attendant must be\n",
            "  qualified to provide the type of assistance certified as medically necessary by\n",
            "  the Member’s attending healthcare provider prior to\n",
            "  transport. For Members with minor children, if the Member is the sole caregiver\n",
            "  of minor child/children at the time of the scheduled appointment, the\n",
            "  Contractor shall authorize transport of the additional minor child/children.\n",
            "  The Contractor is not responsible for providing car seats for Members or\n",
            "  Member’s minor children. The Contractor shall maintain detailed procedures for\n",
            "  screening all NET request types and submit to DOM upon request. The Contractor\n",
            "  shall maintain a procedure for ensuring transport of Members and their minor\n",
            "  child/children at the time of the scheduled appointment. The procedure must\n",
            "  specifically address how the Contractor works with NET Providers regarding\n",
            "  transport of additional passengers that are not covered under this Contract.\n",
            "  The Contractor shall develop and maintain a system of conditional edits to\n",
            "  determine whether a Members is eligible for the transportation requested, based\n",
            "  upon eligibility information to be provided by DOM and/or DOM’s Fiscal Agent.\n",
            "  [Included in the Contract for informational purposes: Not all Mississippi\n",
            "  Medicaid enrollees are eligible for NET Services. The following eligibility\n",
            "  groups are not eligible for NET transportation: Family Planning Waiver, QMB,\n",
            "  QWDI, SLMB, QI-1. The Contractor is not responsible for NET Services rendered to\n",
            "  beneficiaries residing in Long Term Care (LTC) facilities including Nursing Facilities\n",
            "  (NF), Psychiatric Residential Treatment Facility (PRTF), and Intermediate Care\n",
            "  Facilities for Individuals with Intellectual Disabilities (ICF/IID).] The Contractor is\n",
            "  not responsible for arranging the transportation of the remains of a Member who expires\n",
            "  while receiving medical treatment. If a Member expires while in transit, the\n",
            "  Contractor’s NET Provider should contact the nearest law enforcement agency for\n",
            "  instructions.\n",
            "\n",
            "RESULT 3/5  [Score: 1.0]\n",
            "====================================================================================================\n",
            "PAGE: 91  SECTION: SECTION 7\n",
            "PATH: SECTION 7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  SECTION 7 – PROVIDER NETWORK The Contractor must submit\n",
            "  reports related to Provider Networks in accordance with\n",
            "  Section 11, Reporting Requirements, and Exhibit H, Reporting Requirements, of\n",
            "  this Contract. A. General Requirements The Contractor and its Subcontractor or\n",
            "  delegated vendors shall recruit and maintain a Provider\n",
            "  Network, using Provider contracts as approved by the\n",
            "  Division. The Contractor must comply with federal regulations regarding\n",
            "  Provider Network adequacy as stated in 42 C.F.R. §§ 438.68,\n",
            "  438.206, 438.207; and must comply with state regulations regarding Page 91 of\n",
            "  286\n",
            "\n",
            "RESULT 4/5  [Score: 0.99]\n",
            "====================================================================================================\n",
            "PAGE: 123  SECTION: 1. General Requirements\n",
            "PATH: 1. General Requirements\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  MSDH on PHRM/ISS and providing additional case management to identified Members in a\n",
            "  format to be specified by the Division. B. Transitional Care Management.\n",
            "  1. General Requirements Contractor shall maintain and operate a formalized\n",
            "  Transitional Care Management program to support Members’ transition of care\n",
            "  when discharged from an institutional clinic or inpatient setting to include,\n",
            "  but not limited to: a. Collaborating with hospital discharge planners, primary\n",
            "  care and Behavioral Health staff; b. Ensuring appropriate home-based support\n",
            "  and services are available and delivered in a timely manner; c. Implementing\n",
            "  medication reconciliation in concert with the PCP, Behavioral Health/Substance\n",
            "  Use Disorder provider and network pharmacist to assure\n",
            "  continuation of needed therapy following inpatient discharge; d. Notify PCP,\n",
            "  Behavioral Health/Substance Use Disorder provider, or other\n",
            "  specialist within fourteen (14) days of Member’s discharge from inpatient\n",
            "  setting to allow for follow-up appointments to be made; a. Ensuring that the\n",
            "  Member receives the necessary supportive equipment and supplies without undue\n",
            "  delay; Page 123 of 286\n",
            "\n",
            "RESULT 5/5  [Score: 0.49]\n",
            "====================================================================================================\n",
            "PAGE: 78  SECTION: 1. Provider\n",
            "PATH: 1. Provider\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  1. Provider’s name as well as any group affiliation;\n",
            "  2. Street address(es);.\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "\u001b[36mPress Enter to continue to the next query...\u001b[0m\n",
            "\n",
            "QUERY 2/4: What are the Key Medicaid Regulations?\n",
            "\n",
            "====================================================================================================\n",
            "SEARCH QUERY: What are the Key Medicaid Regulations?\n",
            "====================================================================================================\n",
            "\n",
            "Found 5 relevant results:\n",
            "\n",
            "RESULT 1/5  [Score: 1.0]\n",
            "====================================================================================================\n",
            "PAGE: 31  SECTION: 43. Health Care Services\n",
            "PATH: 43. Health Care Services\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  42. Grievance and Appeal System: The processes the Contractor implements to handle\n",
            "  Appeals of an Adverse Benefit Determination and Grievances, as well as the processes to\n",
            "  collect and track information about them.\n",
            "  43. Health Care Services: All Medicaid services provided by a\n",
            "  Contractor under contract with the State Medicaid agency in\n",
            "  any setting, including but not limited to medical care, behavioral health care,\n",
            "  and supports. Page 31 of 286\n",
            "\n",
            "RESULT 2/5  [Score: 1.0]\n",
            "====================================================================================================\n",
            "PAGE: 106  SECTION: 1. Denying or not providing a Member any Medicaid covered service or availability of a\n",
            "PATH: 1. Denying or not providing a Member any Medicaid covered service or availability of a\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  Mainstreaming The Contractor must ensure that network Providers do not intentionally\n",
            "  segregate their Members in any way from other persons receiving services. The Contractor\n",
            "  must investigate Complaints regarding Providers and take affirmative action so that\n",
            "  Members are provided covered services without regard to race, color, national origin,\n",
            "  sex, sexual orientation, gender identity, disability, creed, religion, age, ancestry,\n",
            "  marital status, language, health status, disease or pre-existing condition (including\n",
            "  genetic information), anticipated need for health care or physical or behavioral/mental\n",
            "  disorders, except where medically indicated. Examples of prohibited practices include,\n",
            "  but are not limited to, the following:.\n",
            "  1. Denying or not providing a Member any Medicaid covered\n",
            "  service or availability of a facility within the Contractor’s network. Health\n",
            "  care and treatment necessary to preserve life must be provided to all Members\n",
            "  who are not terminally ill or permanently unconscious, except where a competent\n",
            "  Member objects to such care on his/her own behalf.\n",
            "  2. Subjecting a Member to segregated, separate, or different treatment, including a\n",
            "  different place or time from that provided to other Members, public or private patients,\n",
            "  in any manner related to the receipt of any Medicaid covered service, except where\n",
            "  medically necessary.\n",
            "\n",
            "RESULT 3/5  [Score: 0.9]\n",
            "====================================================================================================\n",
            "PAGE: 182  SECTION: 6. Civil money penalties of up to twenty\n",
            "PATH: 6. Civil money penalties of up to twenty\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  5. Civil money penalties of up to twenty-five thousand dollars ($25,000.00) for\n",
            "  misrepresentation or falsification of information furnished to individuals or Providers,\n",
            "  or for failure to comply with the requirements for physician incentive plans, as set\n",
            "  forth (for Medicare) in 42 C.F.R. §§ 422.208 and 422.210, or the Division determines\n",
            "  that the Contractor has distributed directly, or indirectly through any agent or\n",
            "  independent contractor, Marketing materials that have not been approved by the Division\n",
            "  or that contain false or materially misleading information.\n",
            "  6. Civil money penalties of up to twenty-five thousand dollars ($25,000.00), or\n",
            "  double the amount of excess charges, whichever is greater, for premiums or\n",
            "  charges in excess of the amounts permitted under the Medicaid\n",
            "  program.\n",
            "  7. Temporary management upon a finding by the Division that the Contractor has\n",
            "  repeatedly failed to meet substantive requirements of this Contract, there is continued\n",
            "  egregious behavior by the Contractor, there is substantial risk to the health of\n",
            "  Members, or it is necessary to ensure the health of the Members, in accordance with §\n",
            "  1932 of the Social Security Act;.\n",
            "\n",
            "RESULT 4/5  [Score: 0.76]\n",
            "====================================================================================================\n",
            "PAGE: 40  SECTION: 7. CMS\n",
            "PATH: 7. CMS\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  6. CLIA – Clinical Laboratory Improvement Amendments.\n",
            "  7. CMS – Centers for Medicare and Medicaid Services\n",
            "  8. COE – Category of Eligibility.\n",
            "\n",
            "RESULT 5/5  [Score: 0.71]\n",
            "====================================================================================================\n",
            "PAGE: 96  SECTION: 8. Accessibility Considerations\n",
            "PATH: 8. Accessibility Considerations\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  7. Family Planning The Contractor shall demonstrate that its network includes sufficient\n",
            "  family planning providers to ensure timely access to covered services.\n",
            "  8. Accessibility Considerations The Contractor must ensure that Network\n",
            "  Providers provide physical access, reasonable accommodations, and accessible\n",
            "  equipment for Medicaid enrollees with physical or mental\n",
            "  disabilities.\n",
            "  9. Additional Requirements The Contractor's Provider Network shall reflect, to the\n",
            "  extent possible, the diversity of cultural and ethnic backgrounds of the population\n",
            "  served, including those with limited English proficiency. The Contractor must also\n",
            "  consider the expected utilization of services, given the characteristics and health care\n",
            "  needs of the population.\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "QUERY 3/4: What are the Service Delivery Time Requirements?\n",
            "\n",
            "====================================================================================================\n",
            "SEARCH QUERY: What are the Service Delivery Time Requirements?\n",
            "====================================================================================================\n",
            "\n",
            "Found 5 relevant results:\n",
            "\n",
            "RESULT 1/5  [Score: 1.0]\n",
            "====================================================================================================\n",
            "PAGE: 251  SECTION: 5. The Contractor shall report the above requirements to DOM via a monthly deliverable\n",
            "PATH: 5. The Contractor shall report the above requirements to DOM via a monthly deliverable\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  4. The Contractor shall contact an appropriate NET Provider so that pick-up occurs\n",
            "  within three (3) hours after notification of a hospital discharge.\n",
            "  5. The Contractor shall report the above requirements to DOM via a monthly\n",
            "  deliverable report. The Contractor shall authorize and schedule routine NET\n",
            "  services for ninety-eight percent (98%) of all requests within three (3)\n",
            "  business days after receipt of the request. Contractor shall authorize and\n",
            "  schedule routine NET services for one hundred percent (100%) of all requests\n",
            "  within ten (10) business days after receipt of a request. The Contractor shall\n",
            "  report these requirements to the Division via a monthly Deliverable report. If\n",
            "  the Contractor requires additional information to authorize a request, the\n",
            "  Contractor shall place the request on hold and shall request the additional\n",
            "  information within twenty-four (24) hours after receipt of the request. The\n",
            "  Contractor shall specify the date by which the additional information must be\n",
            "  submitted. Timely requests by the Contractor for additional information shall\n",
            "  stay the authorization period. If the Contractor does not receive additional\n",
            "  information by the date specified by the Contractor, the Contractor shall deny\n",
            "  the request except NET services to an appointment for chemotherapy, dialysis,\n",
            "  and high-risk pregnancy. In those instances, the Contractor shall authorize\n",
            "  Single Trips and pursue receipt of necessary information to authorize a\n",
            "  Standing Order. E. Appropriate Modes of Transportation The following modes of\n",
            "  transportation are to be used in NET Brokerage Program:\n",
            "  1. Ambulatory Page 249 of 286.\n",
            "\n",
            "RESULT 2/5  [Score: 0.82]\n",
            "====================================================================================================\n",
            "PAGE: 250  SECTION: NET P\n",
            "PATH: NET P\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  1. The Contractor shall ensure: a. The average monthly Member waiting time for pick-up\n",
            "  at their originating site (example: home) does not exceed fifteen (15) minutes based on\n",
            "  the scheduled time of pick-up for each.\n",
            "  NET Provider. b. The average monthly Member waiting time for\n",
            "  pick-up (scheduled pick-up) from their medically necessary covered\n",
            "  service (example: appointment, pharmacy, screening, doctors\n",
            "  visit) does not exceed thirty (30) minutes for each NET Provider. c. The\n",
            "  average monthly Member waiting time for pick-up (will-call\n",
            "  pick-up) from their medically necessary covered service\n",
            "  (example: appointment, pharmacy, screening, doctors visit) does not exceed\n",
            "  sixty (60) minutes for each NET Provider. A will-call is defined as a Member’s\n",
            "  call to request the return ride or “will-call” trip. Page 248 of 286\n",
            "\n",
            "RESULT 3/5  [Score: 0.72]\n",
            "====================================================================================================\n",
            "PAGE: 250  SECTION: 1. The Contractor shall ensure\n",
            "PATH: 1. The Contractor shall ensure\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  D. Scheduling and Dispatching Trips The Contractor shall receive requests for NET\n",
            "  Services, screen each request and, if authorized, schedule and assign the trip to an\n",
            "  appropriate NET Provider. The following standards must be maintained and the Contractor\n",
            "  shall report these requirements to the Division via a monthly Deliverable report.\n",
            "  1. The Contractor shall ensure: a. The average monthly Member waiting\n",
            "  time for pick-up at their originating site (example: home)\n",
            "  does not exceed fifteen (15) minutes based on the scheduled\n",
            "  time of pick-up for each\n",
            "  NET Provider. b. The average monthly Member waiting time for pick-up (scheduled pick-up)\n",
            "  from their medically necessary covered service (example: appointment, pharmacy,\n",
            "  screening, doctors visit) does not exceed thirty (30) minutes for each NET Provider. c.\n",
            "  The average monthly Member waiting time for pick-up (will-call pick-up) from their\n",
            "  medically necessary covered service (example: appointment, pharmacy, screening, doctors\n",
            "  visit) does not exceed sixty (60) minutes for each NET Provider.\n",
            "\n",
            "RESULT 4/5  [Score: 0.67]\n",
            "====================================================================================================\n",
            "PAGE: 251  SECTION: 3. The Contractor shall notify the NET Provider of the assignment at least two\n",
            "PATH: 3. The Contractor shall notify the NET Provider of the assignment at least two\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  2. The Contractor and a NET Provider may group Members and trips to promote efficiency\n",
            "  and cost effectiveness. The Contractor may contact Providers in this process.\n",
            "  3. The Contractor shall notify the NET Provider of the assignment at least two\n",
            "  (2) business days prior to the trip, if possible, and at minimum one (1)\n",
            "  business day prior to the trip, with the exception of urgent or high risk\n",
            "  trips, and shall timely assign the trip to another NET Provider if necessary.\n",
            "  4. The Contractor shall contact an appropriate NET Provider so that pick-up occurs\n",
            "  within three (3) hours after notification of a hospital discharge.\n",
            "\n",
            "RESULT 5/5  [Score: 0.49]\n",
            "====================================================================================================\n",
            "PAGE: 256  SECTION: 10. Pick\n",
            "PATH: 10. Pick\n",
            "----------------------------------------------------------------------------------------------------\n",
            "  10. Pick-up and delivery standards;\n",
            "  11. Urgent and High Risk Trip requirements;.\n",
            "\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "import pdfplumber\n",
        "import re\n",
        "import numpy as np\n",
        "import faiss\n",
        "import json\n",
        "from typing import List, Dict\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from rank_bm25 import BM25Okapi\n",
        "import logging\n",
        "import os\n",
        "import textwrap\n",
        "from colorama import Fore, Back, Style, init\n",
        "import math\n",
        "\n",
        "# Initialize colorama for cross-platform colored terminal output\n",
        "init(autoreset=True)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Improvements to extract_text_with_sections function\n",
        "def extract_text_with_sections(pdf_path: str) -> List[Dict]:\n",
        "    documents = []\n",
        "    # More specific section pattern to capture hierarchical section structure\n",
        "    section_pattern = re.compile(r'^([A-Z][A-Z\\s]{2,}(?:\\s*\\d*\\.?\\d*)?|(?:\\d+\\.)+\\s+[A-Za-z][\\w\\s]+)')\n",
        "    current_section = \"\"\n",
        "    section_hierarchy = {}\n",
        "\n",
        "    try:\n",
        "        if not os.path.exists(pdf_path):\n",
        "            raise FileNotFoundError(f\"PDF file not found at: {pdf_path}\")\n",
        "\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page_num, page in enumerate(pdf.pages):\n",
        "                try:\n",
        "                    text = page.extract_text()\n",
        "                    if not text:\n",
        "                        logger.warning(f\"Empty text on page {page_num + 1}\")\n",
        "                        continue\n",
        "\n",
        "                    # Process page text with improved context preservation\n",
        "                    processed_text = process_page_text(text, page_num, section_pattern, section_hierarchy)\n",
        "\n",
        "                    for section_info in processed_text:\n",
        "                        documents.append({\n",
        "                            \"text\": section_info[\"text\"],\n",
        "                            \"page\": page_num + 1,\n",
        "                            \"section\": section_info[\"section\"],\n",
        "                            \"section_hierarchy\": section_info.get(\"section_hierarchy\", \"\"),\n",
        "                            \"source\": pdf_path\n",
        "                        })\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error processing page {page_num + 1}: {str(e)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error opening PDF: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "    if not documents:\n",
        "        raise ValueError(\"No text could be extracted from the PDF\")\n",
        "\n",
        "    return documents\n",
        "\n",
        "# New helper function to process page text with better context\n",
        "def process_page_text(text: str, page_num: int, section_pattern, section_hierarchy: Dict) -> List[Dict]:\n",
        "    sections = []\n",
        "    lines = text.split('\\n')\n",
        "    current_section = \"\"\n",
        "    current_text = []\n",
        "    section_level = 0\n",
        "\n",
        "    # First pass to identify sections\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        # Skip pure numeric lines and table of contents\n",
        "        if re.match(r'^\\s*\\d+\\s*$', line) or re.search(r'\\s*\\.{3,}\\s*\\d+\\s*$', line):\n",
        "            continue\n",
        "\n",
        "        match = section_pattern.match(line)\n",
        "        if match:\n",
        "            # Save previous section if exists\n",
        "            if current_text and current_section:\n",
        "                sections.append({\n",
        "                    \"section\": current_section,\n",
        "                    \"text\": ' '.join(current_text),\n",
        "                    \"section_hierarchy\": get_section_hierarchy(section_hierarchy, current_section)\n",
        "                })\n",
        "\n",
        "            current_section = match.group(1).strip()\n",
        "            # Detect section level from format (e.g., 2.1.3)\n",
        "            if re.match(r'^\\d+(\\.\\d+)*', current_section):\n",
        "                dots = current_section.count('.')\n",
        "                section_level = dots + 1\n",
        "                update_section_hierarchy(section_hierarchy, current_section, section_level)\n",
        "            current_text = [line]\n",
        "        else:\n",
        "            current_text.append(line)\n",
        "\n",
        "    # Add the last section\n",
        "    if current_text and current_section:\n",
        "        sections.append({\n",
        "            \"section\": current_section,\n",
        "            \"text\": ' '.join(current_text),\n",
        "            \"section_hierarchy\": get_section_hierarchy(section_hierarchy, current_section)\n",
        "        })\n",
        "\n",
        "    # Second pass to clean and process text\n",
        "    for i in range(len(sections)):\n",
        "        text = sections[i][\"text\"]\n",
        "        # Improved text cleaning\n",
        "        text = re.sub(r'\\.{2,}', '.', text)  # Replace multiple dots\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        text = re.sub(r'\\s*andor\\s*', ' and/or ', text)  # Fix \"andor\" spacing\n",
        "        sections[i][\"text\"] = text\n",
        "\n",
        "    return sections\n",
        "\n",
        "# Helper functions for section hierarchy\n",
        "def update_section_hierarchy(hierarchy: Dict, section: str, level: int) -> None:\n",
        "    \"\"\"Update the section hierarchy dictionary with the current section\"\"\"\n",
        "    if level == 1:\n",
        "        hierarchy[\"current\"] = section\n",
        "        hierarchy[\"sub\"] = {}\n",
        "    elif level == 2 and \"current\" in hierarchy:\n",
        "        if \"sub\" not in hierarchy:\n",
        "            hierarchy[\"sub\"] = {}\n",
        "        hierarchy[\"sub\"][\"current\"] = section\n",
        "    # Handle deeper levels as needed\n",
        "\n",
        "def get_section_hierarchy(hierarchy: Dict, section: str) -> str:\n",
        "    \"\"\"Get the full hierarchical path of a section\"\"\"\n",
        "    if \"current\" not in hierarchy:\n",
        "        return section\n",
        "\n",
        "    if \"sub\" in hierarchy and \"current\" in hierarchy[\"sub\"]:\n",
        "        return f\"{hierarchy['current']} > {hierarchy['sub']['current']}\"\n",
        "\n",
        "    return hierarchy[\"current\"]\n",
        "\n",
        "def clean_and_chunk(\n",
        "    documents: List[Dict],\n",
        "    max_chunk_size: int = 300,\n",
        "    overlap_ratio: float = 0.30  # **30% overlap for better context retention**\n",
        ") -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Efficient chunking strategy with 30% overlapping chunks to improve context retention.\n",
        "\n",
        "    Parameters:\n",
        "    - documents (List[Dict]): Extracted text sections.\n",
        "    - max_chunk_size (int): Maximum words per chunk.\n",
        "    - overlap_ratio (float): Overlapping ratio (default: 30% of chunk size).\n",
        "\n",
        "    Returns:\n",
        "    - List[Dict]: Chunked document sections with metadata.\n",
        "    \"\"\"\n",
        "\n",
        "    chunks = []\n",
        "    overlap_size = int(max_chunk_size * overlap_ratio)  # **30% overlap calculation**\n",
        "\n",
        "    for doc in documents:\n",
        "        text = doc['text']\n",
        "        section = doc.get('section', '')\n",
        "        section_hierarchy = doc.get('section_hierarchy', '')\n",
        "\n",
        "        words = text.split()  # **Faster than regex-based sentence splitting**\n",
        "        num_words = len(words)\n",
        "\n",
        "        # **Use a sliding window to generate chunks efficiently**\n",
        "        start = 0\n",
        "        while start < num_words:\n",
        "            end = min(start + max_chunk_size, num_words)\n",
        "            chunk_text = \" \".join(words[start:end])\n",
        "\n",
        "            chunks.append({\n",
        "                \"text\": chunk_text,\n",
        "                \"metadata\": {\n",
        "                    \"page\": doc[\"page\"],\n",
        "                    \"section\": section,\n",
        "                    \"section_hierarchy\": section_hierarchy,\n",
        "                    \"source\": doc[\"source\"]\n",
        "                }\n",
        "            })\n",
        "\n",
        "            if end == num_words:\n",
        "                break  # Stop if we've reached the end of the document\n",
        "\n",
        "            start += max_chunk_size - overlap_size  # **Move forward with 30% overlap**\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# def clean_text(text: str) -> str:\n",
        "#     \"\"\"Enhanced text cleaning function\"\"\"\n",
        "#     text = re.sub(r'\\s*\\.+\\s*\\d+\\s*$', '', text, flags=re.MULTILINE)\n",
        "#     text = re.sub(r'\\.{2,}', '.', text)\n",
        "#     text = re.sub(r'\\.\\s*\\.$', '.', text)\n",
        "#     text = re.sub(r'\\s*\\n\\s*', ' ', text)\n",
        "#     text = re.sub(r'\\s+', ' ', text)\n",
        "#     text = re.sub(r'\\s*andor\\s*', ' and/or ', text)\n",
        "#     text = re.sub(r'\\s*\\d+\\s*$', '', text)\n",
        "\n",
        "#     return text.strip()\n",
        "\n",
        "\n",
        "def split_into_sentences(text: str) -> List[str]:\n",
        "    \"\"\"Better sentence splitting logic for legal documents\"\"\"\n",
        "    # Handle common abbreviations to prevent wrong splits\n",
        "    text = re.sub(r'(\\b(?:Mr|Mrs|Ms|Dr|St|Co|Inc|Ltd|i\\.e|e\\.g)\\.)(\\s)', r'\\1TEMP_MARKER\\2', text)\n",
        "\n",
        "    # Split by sentence endings\n",
        "    sentences = []\n",
        "    for part in re.split(r'([.!?])\\s+(?=[A-Z])', text):\n",
        "        if part in ['.', '!', '?']:\n",
        "            sentences[-1] += part\n",
        "        elif part:\n",
        "            sentences.append(part)\n",
        "\n",
        "    # Restore abbreviation markers\n",
        "    sentences = [s.replace('TEMP_MARKER', '') for s in sentences]\n",
        "\n",
        "    # Clean and normalize sentences\n",
        "    sentences = [s.strip() for s in sentences if s.strip()]\n",
        "    sentences = [s + ('.' if not s.endswith(('.', '!', '?')) else '') for s in sentences]\n",
        "\n",
        "    return sentences\n",
        "\n",
        "def create_faiss_index(embeddings: np.ndarray, chunks: List[Dict]) -> faiss.Index:\n",
        "   index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "   index.add(embeddings.astype(np.float32))\n",
        "\n",
        "   metadata = [{\n",
        "       \"text\": chunk[\"text\"],\n",
        "       \"page\": chunk[\"metadata\"][\"page\"],\n",
        "       \"section\": chunk[\"metadata\"][\"section\"],\n",
        "       \"section_hierarchy\": chunk[\"metadata\"].get(\"section_hierarchy\", \"\"),\n",
        "       \"source\": chunk[\"metadata\"][\"source\"]\n",
        "   } for chunk in chunks]\n",
        "\n",
        "   with open(\"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "       json.dump(metadata, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "   return index\n",
        "\n",
        "def _print_formatted_results(self, results: List[Dict]) -> None:\n",
        "    \"\"\"\n",
        "    Display search results in a well-formatted, reader-friendly way\n",
        "    \"\"\"\n",
        "    if not results:\n",
        "        print(f\"\\n{Fore.YELLOW}No results found.{Style.RESET_ALL}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n{Fore.GREEN}{Style.BRIGHT}Found {len(results)} relevant results:{Style.RESET_ALL}\")\n",
        "\n",
        "    # Display result count summary\n",
        "    for i, result in enumerate(results, 1):\n",
        "        # Format header with consistent spacing and visual separation\n",
        "        print(f\"\\n{Fore.BLUE}{Style.BRIGHT}RESULT {i}/{len(results)}{Style.RESET_ALL}  {Fore.YELLOW}[Score: {result['score']}]{Style.RESET_ALL}\")\n",
        "        print(f\"{Fore.WHITE}{Style.BRIGHT}{'='*100}{Style.RESET_ALL}\")\n",
        "\n",
        "        # Location information\n",
        "        print(f\"{Fore.CYAN}PAGE:{Style.RESET_ALL} {result['page']}  {Fore.CYAN}SECTION:{Style.RESET_ALL} {result['section']}\")\n",
        "\n",
        "        # Section hierarchy if available\n",
        "        if result.get('section_hierarchy'):\n",
        "            print(f\"{Fore.CYAN}PATH:{Style.RESET_ALL} {result['section_hierarchy']}\")\n",
        "\n",
        "        print(f\"{Fore.WHITE}{Style.BRIGHT}{'-'*100}{Style.RESET_ALL}\")\n",
        "\n",
        "        # Format and print context before if available\n",
        "        if result.get('context', {}).get('before'):\n",
        "            before_text = result['context']['before']\n",
        "            wrapped_before = textwrap.fill(\n",
        "                before_text,\n",
        "                width=90,\n",
        "                initial_indent=\"  \",\n",
        "                subsequent_indent=\"  \"\n",
        "            )\n",
        "            print(f\"{Fore.WHITE}{wrapped_before}{Style.RESET_ALL}\")\n",
        "\n",
        "        # Format and print main text with highlighted terms\n",
        "        main_text = self.highlight_terms(result['text'], result['key_terms'])\n",
        "\n",
        "        # Use textwrap.wrap instead of fill to get a list of lines\n",
        "        wrapped_lines = textwrap.wrap(\n",
        "            main_text,\n",
        "            width=90,\n",
        "            initial_indent=\"  \",\n",
        "            subsequent_indent=\"  \"\n",
        "        )\n",
        "\n",
        "        # Print each line with proper formatting\n",
        "        for line in wrapped_lines:\n",
        "            print(f\"{Fore.WHITE}{Style.BRIGHT}{line}{Style.RESET_ALL}\")\n",
        "\n",
        "        # Format and print context after if available\n",
        "        if result.get('context', {}).get('after'):\n",
        "            after_text = result['context']['after']\n",
        "            wrapped_after = textwrap.fill(\n",
        "                after_text,\n",
        "                width=90,\n",
        "                initial_indent=\"  \",\n",
        "                subsequent_indent=\"  \"\n",
        "            )\n",
        "            print(f\"{Fore.WHITE}{wrapped_after}{Style.RESET_ALL}\")\n",
        "\n",
        "    print(f\"\\n{Fore.WHITE}{Style.BRIGHT}{'='*100}{Style.RESET_ALL}\")\n",
        "\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def compute_cosine_similarity(self, text1: str, text2: str) -> float:\n",
        "    \"\"\"\n",
        "    Compute cosine similarity between two text chunks using their embeddings.\n",
        "    \"\"\"\n",
        "    embedding1 = self.model.encode(text1, normalize_embeddings=True)\n",
        "    embedding2 = self.model.encode(text2, normalize_embeddings=True)\n",
        "    return cosine_similarity([embedding1], [embedding2])[0][0]\n",
        "\n",
        "# Improved MedicaidRetriever class\n",
        "class MedicaidRetriever:\n",
        "    def __init__(self, index_path: str, metadata_path: str):\n",
        "        self.index = faiss.read_index(index_path)\n",
        "        # self.model = SentenceTransformer('BAAI/bge-large-en-v1.5')\n",
        "        self.model = SentenceTransformer('BAAI/bge-base-en-v1.5')  # Updated model\n",
        "\n",
        "        with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            self.metadata = json.load(f)\n",
        "\n",
        "        texts = [doc[\"text\"] for doc in self.metadata]\n",
        "        self.bm25 = BM25Okapi([text.split() for text in texts])\n",
        "\n",
        "        # Create section index for better filtering\n",
        "        self.section_index = {}\n",
        "        for i, doc in enumerate(self.metadata):\n",
        "            section = doc.get(\"section\", \"\")\n",
        "            if section:\n",
        "                if section not in self.section_index:\n",
        "                    self.section_index[section] = []\n",
        "                self.section_index[section].append(i)\n",
        "\n",
        "\n",
        "    def hybrid_search(self, query: str, top_k: int = 5, filter_section: str = None) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Perform a hybrid search using both semantic and BM25 ranking\n",
        "        \"\"\"\n",
        "        # Print query header with better formatting\n",
        "        print(\"\\n\" + \"=\"*100)\n",
        "        print(f\"{Fore.CYAN}{Style.BRIGHT}SEARCH QUERY: {query}{Style.RESET_ALL}\")\n",
        "        print(\"=\"*100)\n",
        "\n",
        "        # Extract key terms for highlighting\n",
        "        key_terms = set(term.lower() for term in query.split() if len(term) > 3)\n",
        "\n",
        "        # Generate query embedding\n",
        "        query_embedding = self.model.encode(query, normalize_embeddings=True).reshape(1, -1)\n",
        "\n",
        "        # Get more results initially for filtering\n",
        "        semantic_scores, indices = self.index.search(query_embedding.astype(np.float32), top_k * 3)\n",
        "        bm25_scores = self.bm25.get_scores(query.split())\n",
        "\n",
        "        # Filter indices by section if needed\n",
        "        if filter_section and filter_section in self.section_index:\n",
        "            section_indices = set(self.section_index[filter_section])\n",
        "            indices = [idx for idx in indices[0] if idx in section_indices]\n",
        "        else:\n",
        "            indices = indices[0]\n",
        "\n",
        "        results = []\n",
        "        seen_texts = set()\n",
        "\n",
        "        for idx in indices:\n",
        "            if idx >= len(self.metadata):\n",
        "                continue\n",
        "\n",
        "            result = self.metadata[idx]\n",
        "            text = result[\"text\"]\n",
        "\n",
        "            # Skip if this is too similar to already seen text\n",
        "            if any(self.text_similarity(text, seen) > 0.8 for seen in seen_texts):\n",
        "                continue\n",
        "\n",
        "            if text not in seen_texts:\n",
        "                sem_score = semantic_scores[0][list(indices).index(idx)] if idx in indices else 10.0\n",
        "                bm25_score = bm25_scores[idx]\n",
        "\n",
        "                # Improved hybrid scoring\n",
        "                hybrid_score = self.calculate_hybrid_score(sem_score, bm25_score, max(bm25_scores), text, key_terms)\n",
        "\n",
        "                # hybrid_score = self.calculate_hybrid_score(\n",
        "                #                 sem_score,\n",
        "                #                 bm25_score,\n",
        "                #                 max(bm25_scores),\n",
        "                #                 text,\n",
        "                #                 key_terms,\n",
        "                #                 query=query,\n",
        "                #                 section=result.get('section', '')\n",
        "                #             )\n",
        "                # Find context before and after for better understanding\n",
        "                context = self.find_context(idx, query)\n",
        "\n",
        "                results.append({\n",
        "                    'page': result['page'],\n",
        "                    'section': result.get('section', ''),\n",
        "                    'section_hierarchy': result.get('section_hierarchy', ''),\n",
        "                    'text': text,  # Store original text\n",
        "                    'key_terms': key_terms,  # Store key terms for highlighting\n",
        "                    'context': context,\n",
        "                    'score': round(hybrid_score, 2)\n",
        "                })\n",
        "                seen_texts.add(text)\n",
        "\n",
        "            if len(results) >= top_k:\n",
        "                break\n",
        "\n",
        "        # Sort results by score (highest first)\n",
        "        results = sorted(results, key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "        # Pretty-print the results\n",
        "        self._print_formatted_results(results)\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "    def _print_formatted_results(self, results: List[Dict]) -> None:\n",
        "        \"\"\"\n",
        "        Display search results in a well-formatted, reader-friendly way\n",
        "        \"\"\"\n",
        "        if not results:\n",
        "            print(f\"\\n{Fore.YELLOW}No results found.{Style.RESET_ALL}\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\n{Fore.GREEN}{Style.BRIGHT}Found {len(results)} relevant results:{Style.RESET_ALL}\")\n",
        "\n",
        "        # Display result count summary\n",
        "        for i, result in enumerate(results, 1):\n",
        "            # Format header with consistent spacing and visual separation\n",
        "            print(f\"\\n{Fore.BLUE}{Style.BRIGHT}RESULT {i}/{len(results)}{Style.RESET_ALL}  {Fore.YELLOW}[Score: {result['score']}]{Style.RESET_ALL}\")\n",
        "            print(f\"{Fore.WHITE}{Style.BRIGHT}{'='*100}{Style.RESET_ALL}\")\n",
        "\n",
        "            # Location information\n",
        "            print(f\"{Fore.CYAN}PAGE:{Style.RESET_ALL} {result['page']}  {Fore.CYAN}SECTION:{Style.RESET_ALL} {result['section']}\")\n",
        "\n",
        "            # Section hierarchy if available\n",
        "            if result.get('section_hierarchy'):\n",
        "                print(f\"{Fore.CYAN}PATH:{Style.RESET_ALL} {result['section_hierarchy']}\")\n",
        "\n",
        "            print(f\"{Fore.WHITE}{Style.BRIGHT}{'-'*100}{Style.RESET_ALL}\")\n",
        "\n",
        "            # Format and print context before if available\n",
        "            if result.get('context', {}).get('before'):\n",
        "                before_text = result['context']['before']\n",
        "                wrapped_before = textwrap.fill(\n",
        "                    before_text,\n",
        "                    width=90,\n",
        "                    initial_indent=\"  \",\n",
        "                    subsequent_indent=\"  \"\n",
        "                )\n",
        "                print(f\"{Fore.WHITE}{wrapped_before}{Style.RESET_ALL}\")\n",
        "\n",
        "            # Format and print main text with highlighted terms\n",
        "            main_text = self.highlight_terms(result['text'], result['key_terms'])\n",
        "            wrapped_main = textwrap.fill(\n",
        "                main_text,\n",
        "                width=90,\n",
        "                initial_indent=f\"{Fore.WHITE}{Style.BRIGHT}  \",\n",
        "                subsequent_indent=f\"{Fore.WHITE}{Style.BRIGHT}  \"\n",
        "            )\n",
        "            print(wrapped_main)\n",
        "\n",
        "            # Format and print context after if available\n",
        "            if result.get('context', {}).get('after'):\n",
        "                after_text = result['context']['after']\n",
        "                wrapped_after = textwrap.fill(\n",
        "                    after_text,\n",
        "                    width=90,\n",
        "                    initial_indent=\"  \",\n",
        "                    subsequent_indent=\"  \"\n",
        "                )\n",
        "                print(f\"{Fore.WHITE}{wrapped_after}{Style.RESET_ALL}\")\n",
        "\n",
        "        print(f\"\\n{Fore.WHITE}{Style.BRIGHT}{'='*100}{Style.RESET_ALL}\")\n",
        "\n",
        "    def calculate_hybrid_score(self, sem_score: float, bm25_score: float, max_bm25: float, text: str, key_terms: set, query: str = None, section: str = None) -> float:\n",
        "        \"\"\"Enhanced scoring balancing relevance and completeness\"\"\"\n",
        "        # Base scores - give more weight to BM25 for keyword matching while keeping semantic relevance\n",
        "        semantic_component = 1 - sem_score/10  # Convert distance to similarity score\n",
        "        bm25_component = bm25_score / max(max_bm25, 0.001)  # Avoid division by zero\n",
        "\n",
        "        # Adjust weighting between semantic and lexical scores\n",
        "        hybrid_score = (0.4 * semantic_component) + (0.6 * bm25_component)\n",
        "\n",
        "        # Calculate term density with higher emphasis\n",
        "        term_count = sum(1 for term in key_terms if term.lower() in text.lower())\n",
        "        term_density = term_count / max(1, len(text.split()))\n",
        "        term_bonus = term_density * 0.25  # Moderate term density bonus\n",
        "\n",
        "        # Major bonus for content length - we want comprehensive answers\n",
        "        # Using a logarithmic scale to reward longer content but with diminishing returns\n",
        "        length_factor = min(1.0, 0.3 * math.log(1 + len(text)/200))\n",
        "        length_bonus = length_factor * 0.4  # Substantial length bonus\n",
        "\n",
        "        # Relevance boost for section titles matching query terms\n",
        "        section_bonus = 0\n",
        "        if section and key_terms:\n",
        "            section_lower = section.lower()\n",
        "            section_matches = sum(1 for term in key_terms if term in section_lower)\n",
        "            if section_matches > 0:\n",
        "                section_bonus = min(0.2, section_matches * 0.08)\n",
        "\n",
        "        # Check for exact query terms appearing in the first 100 characters\n",
        "        # This helps identify passages that directly address the query from the start\n",
        "        intro_text = text[:100].lower()\n",
        "        intro_term_matches = sum(1 for term in key_terms if term in intro_text)\n",
        "        intro_bonus = min(0.15, 0.05 * intro_term_matches)\n",
        "\n",
        "        # Implement a context relevance factor - prefer results that have more contextual information\n",
        "        context_factor = 0\n",
        "        sentences = split_into_sentences(text)\n",
        "        if len(sentences) >= 3:\n",
        "            context_factor = min(0.15, 0.03 * len(sentences))\n",
        "\n",
        "        final_score = hybrid_score + term_bonus + length_bonus + section_bonus + intro_bonus + context_factor\n",
        "\n",
        "        # Apply a small normalization to keep scores in a reasonable range\n",
        "        return min(1.0, final_score)\n",
        "\n",
        "    def find_context(self, idx: int, query: str) -> Dict:\n",
        "        \"\"\"Find surrounding context for better understanding\"\"\"\n",
        "        context = {\"before\": \"\", \"after\": \"\"}\n",
        "\n",
        "        # Look for context before\n",
        "        if idx > 0:\n",
        "            prev_doc = self.metadata[idx-1]\n",
        "            same_page = prev_doc['page'] == self.metadata[idx]['page']\n",
        "            if same_page:\n",
        "                # Take the last part of the previous document - get complete sentences\n",
        "                text = prev_doc['text']\n",
        "                # Call the global function directly\n",
        "                sentences = split_into_sentences(text)\n",
        "                if sentences:\n",
        "                    # Take last 1-3 sentences depending on length\n",
        "                    context[\"before\"] = ' '.join(sentences[-min(3, len(sentences)):])\n",
        "\n",
        "        # Look for context after\n",
        "        if idx < len(self.metadata) - 1:\n",
        "            next_doc = self.metadata[idx+1]\n",
        "            same_page = next_doc['page'] == self.metadata[idx]['page']\n",
        "            if same_page:\n",
        "                # Take the first part of the next document - get complete sentences\n",
        "                text = next_doc['text']\n",
        "                # Call the global function directly\n",
        "                sentences = split_into_sentences(text)\n",
        "                if sentences:\n",
        "                    # Take first 1-3 sentences depending on length\n",
        "                    context[\"after\"] = ' '.join(sentences[:min(3, len(sentences))])\n",
        "\n",
        "        return context\n",
        "\n",
        "\n",
        "    def text_similarity(self, text1: str, text2: str) -> float:\n",
        "        \"\"\"Calculate similarity between two text snippets to avoid redundancy\"\"\"\n",
        "        words1 = set(text1.lower().split())\n",
        "        words2 = set(text2.lower().split())\n",
        "\n",
        "        if not words1 or not words2:\n",
        "            return 0.0\n",
        "\n",
        "        intersection = words1.intersection(words2)\n",
        "        return len(intersection) / max(len(words1), len(words2))\n",
        "\n",
        "    def highlight_terms(self, text: str, key_terms: set) -> str:\n",
        "        \"\"\"Highlight key terms in text for better readability\"\"\"\n",
        "        if not key_terms:\n",
        "            return text\n",
        "\n",
        "        # Use colorama for terminal highlighting\n",
        "        for term in key_terms:\n",
        "            pattern = re.compile(r'\\b' + re.escape(term) + r'\\b', re.IGNORECASE)\n",
        "            text = pattern.sub(f\"{Fore.GREEN}{Style.BRIGHT}\\\\g<0>{Fore.WHITE}{Style.BRIGHT}\", text)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def filter_by_section(self, section_name: str) -> List[int]:\n",
        "        \"\"\"Get document indices for a specific section\"\"\"\n",
        "        if section_name in self.section_index:\n",
        "            return self.section_index[section_name]\n",
        "        return []\n",
        "\n",
        "    def get_common_sections(self) -> List[str]:\n",
        "        \"\"\"Return list of most common sections for filtering\"\"\"\n",
        "        section_counts = {}\n",
        "        for doc in self.metadata:\n",
        "            section = doc.get(\"section\", \"\")\n",
        "            if section:\n",
        "                section_counts[section] = section_counts.get(section, 0) + 1\n",
        "\n",
        "        # Return top sections by count\n",
        "        return [s for s, c in sorted(section_counts.items(), key=lambda x: x[1], reverse=True)[:20]]\n",
        "\n",
        "\n",
        "def initialize_retriever(pdf_path: str = \"michigan_medicaid.pdf\") -> MedicaidRetriever:\n",
        "    \"\"\"\n",
        "    Initialize the retriever by processing the PDF and creating necessary indexes\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"{Fore.CYAN}Processing PDF: {pdf_path}{Style.RESET_ALL}\")\n",
        "        documents = extract_text_with_sections(pdf_path)\n",
        "        print(f\"{Fore.GREEN}Extracted {len(documents)} document sections{Style.RESET_ALL}\")\n",
        "\n",
        "        chunks = clean_and_chunk(documents)\n",
        "        print(f\"{Fore.GREEN}Created {len(chunks)} text chunks for indexing{Style.RESET_ALL}\")\n",
        "\n",
        "        if not chunks:\n",
        "            raise ValueError(\"No valid chunks created from documents\")\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"{Fore.CYAN}Generating embeddings...{Style.RESET_ALL}\")\n",
        "        model = SentenceTransformer('BAAI/bge-base-en-v1.5')  # Updated model\n",
        "        embeddings = model.encode([chunk[\"text\"] for chunk in chunks],\n",
        "                                normalize_embeddings=True,\n",
        "                                show_progress_bar=True)\n",
        "\n",
        "        print(f\"{Fore.CYAN}Creating FAISS index...{Style.RESET_ALL}\")\n",
        "        faiss_index = create_faiss_index(embeddings, chunks)\n",
        "        index_path = \"medicaid.index\"\n",
        "        faiss.write_index(faiss_index, index_path)\n",
        "        print(f\"{Fore.GREEN}Index saved to {index_path}{Style.RESET_ALL}\")\n",
        "\n",
        "        return MedicaidRetriever(index_path, \"metadata.json\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in initialize_retriever: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        print(f\"{Fore.CYAN}{Style.BRIGHT}MEDICAID DOCUMENT SEARCH SYSTEM{Style.RESET_ALL}\")\n",
        "        print(f\"{Fore.CYAN}{'='*100}{Style.RESET_ALL}\")\n",
        "        print(f\"{Fore.WHITE}Initializing retriever...{Style.RESET_ALL}\")\n",
        "\n",
        "        retriever = initialize_retriever()\n",
        "\n",
        "        queries = [\n",
        "            \"What are the Provider Requirements?\",\n",
        "            \"What are the Key Medicaid Regulations?\",\n",
        "            \"What are the Service Delivery Time Requirements?\",\n",
        "            \"What are the Compliance Terms?\"\n",
        "        ]\n",
        "\n",
        "\n",
        "        print(f\"\\n{Fore.CYAN}{Style.BRIGHT}RUNNING SAMPLE QUERIES{Style.RESET_ALL}\")\n",
        "\n",
        "        for i, query in enumerate(queries, 1):\n",
        "            print(f\"\\n{Fore.YELLOW}{Style.BRIGHT}QUERY {i}/{len(queries)}: {query}{Style.RESET_ALL}\")\n",
        "            results = retriever.hybrid_search(query)\n",
        "\n",
        "            # Optional: pause between queries for readability\n",
        "            if i < len(queries):\n",
        "                input(f\"\\n{Fore.CYAN}Press Enter to continue to the next query...{Style.RESET_ALL}\")\n",
        "\n",
        "        print(f\"\\n{Fore.GREEN}{Style.BRIGHT}Search completed successfully.{Style.RESET_ALL}\")\n",
        "        print(f\"\\n{Fore.CYAN}To run your own queries, use:{Style.RESET_ALL}\")\n",
        "\n",
        "\n",
        "        print(f\"retriever.hybrid_search('Your query here', top_k=5)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in main execution: {str(e)}\")\n",
        "        print(f\"\\n{Fore.RED}{Style.BRIGHT}ERROR: {str(e)}{Style.RESET_ALL}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber\n",
        "!pip install faiss-cpu\n",
        "!pip install rank_bm25\n",
        "!pip install colorama\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUWRKb55Kx16",
        "outputId": "9b1b22a3-2ff8-49aa-94cc-758904f438c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.5)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.11/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (1.26.4)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PcFWAIMyNi--"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}